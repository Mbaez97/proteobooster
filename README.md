# ProteoBOOSTER

ProteoBOOSTER is a tool to automatically infer protein-protein interactions (PPI) networks for an entire proteome, and characterize this PPI networks by inferring protein complexes. If functional annotations are avilable for the proteome, complexes are also analyzed for function, providing a functional profile for as many putative complexes as possible.

This repository contains the code to download source databases to do this for any target proteome, as well as the scripts to automatically transfer the network and perform the subsequent analyses. A sister project, ProteoBOOSTER-web, provides a web interface that can display information generated by ProteoBOOSTER on a website.

# Usage

This repository is composed by a series of scripts that should be run in a specific sequence. In between, however, you should run [BLAST](https://blast.ncbi.nlm.nih.gov/doc/blast-help/downloadblastdata.html#blast-executables) and [ClusterONE](https://github.com/ntamas/cl1). Below is an example sequence of commands that runs the pipeline to the _Homo sapiens_ reference proteome:

Install the required packages
```bash
pip install requirements.txt
```

Download the required databases
```bash
python download_sapshot.py <project-path> -s <data-dir> 
```
Here `<project-path>` refers to the directory on your computer where you want to store all the databases, they will be stored in `<project-path>/<data-dir>`.

Next, we need to pre-process the interaction databases and combine it into a single database.
```bash
python create_interaction_file.py <project-path>/<data-dir> <project-path>/interactions
```
This creates a collection of files on the `<project-path>/interactions/<data-dir>` path (although we're changing this behavior soon).

Now, let's assume you've downloaded a proteome fasta file from UniprotKB, such as the _homo sapiens_ reference proteome: `UP000005640_9606.fasta`.

To process this, we need to first create a BLAST database from the fasta that containts all the interactors we've identified before:
```bash
makeblastdb -in <project-path>/interactions/<data-dir>/sequences.fasta -out <project-path>/interactions/<data-dir>/sequences.fasta -dbtype prot
```

Then, we need to align our target fasta file against that database:
```bash
blastp -outfmt 6 -query UP000005640_9606.fasta -out UP000005640_9606.blast -db <project-path>/interactions/<data-dir>/sequences.fasta -num_threads <num-cores>
```
Here `<num-cores` is an optional value to speed up the alignment with the number of cores.

We carry on by applying our homology criterion to build a homolog database for the target proteome:
```bash
python create_homologs.py UP000005640_9606.blast UP000005640_9606.homologs
```

Using the calculated homolog database, we can now transfer interactions from the combined database for our target proteome:
```bash
python transfer_interactions.py UP000005640_9606.homologs <project-path>/interactions/<data-dir>/interaction_file.tab UP000005640_9606.interologs
```

If you know that no experimental interactions are available for your target organism, the next step is optional. For _homo sapiens_ (or any model organism) however, it's very likely that some of the proteins in the reference proteome have annotated interactors, so we extract them to include those in the inferred interaction:
```bash
python extract_experimental_interactions.py UP000005640_9606.fasta <project-path>/interactions/<data-dir>/interaction_file.tab UP000005640_9606.interactions
```

We now have enough data to create a graph and use it to infer protein complexes. Let's get the graph in a format that ClusterONE can use:
```bash
python prepare_data_for_clustering.py UP000005640_9606.interactions UP000005640_9606.interologs UP000005640_9606.graph
```

And then cluster the graph:
```bash
java -jar cluster_one-1.2.jar -F csv UP000005640_9606.graph > UP000005640_9606.complexes
```
